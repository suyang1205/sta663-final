{
 "metadata": {
  "name": "",
  "signature": "sha256:4413b4800042ae4bd47719a040924a5ab62d3a2693fac92c25160641014480d5"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Paper Choice: Bayesian Hierarchical Clustering\n",
      "----\n",
      "Outline of Background\n",
      "----\n",
      "\n",
      "####  What Problem Does It Address?  \n",
      "The tradtional hierarchical clustering method has many limitations, such as the choice of distance metric and the number of clusters. To deal with those problems, the authors come up with a novel algorithm for agglomerative hierarchical clustering based on evaluating marginal likelihoods of a probabilistic model, which has several advantages over traditional distance-based agglomerative clustering algorithms.\n",
      "\n",
      "####  Background of  Hierarchical Clustering\n",
      "#####     Hierarchical Structure\n",
      "Hierarchical structures are ubiquitous in the natural world. They are also a natural representation for data which was not generated by evolutionary\n",
      "processes. \n",
      "- The evolutionary tree of living organisms.\n",
      "- Internet newsgroups, emails, or documents from a newswire, can be organized in increasingly broad topic domains.\n",
      "\n",
      "#####     Traditional Hierarchical Clustering\n",
      "The traditional method for hierarchically clustering  is a bottomup agglomerative algorithm. It starts with each data point assigned to its own cluster and iteratively merges the two closest clusters together until all the data belongs to a single cluster. The nearest pair of clusters is chosen based on a given distance measure (e.g. Euclidean distance between cluster means, or distance between nearest points).\n",
      "\n",
      "#####     Limitations of Traditional Hierarchical Clustering\n",
      "\n",
      "- The algorithm provides no guide to choosing the \u201ccorrect\u201d number of clusters or the level at which to prune the tree. \n",
      "- It is often dif\ufb01cult to know which distance metric to choose, especially for structured data such as images or sequences.\n",
      "- The traditional algorithm does not de\ufb01ne a probabilistic model of the data, so it is hard to ask how \u201cgood\u201da clustering is, to compare to other    models, to make predictions and cluster new data into an existing hierarchy\n",
      "\n",
      "###  Bayesian Hierarchical Clustering\n",
      "Bayesian hierarchical clustering algorithm uses marginal likelihoods to decide which clusters to merge and to avoid over\ufb01tting. Basically it asks what the probability is that all the data in a potential merge were generated from the same mixture component, and compares this to exponentially many hypotheses at lower levels of the tree\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}